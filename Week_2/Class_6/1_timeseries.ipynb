{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T14:58:27.430217Z",
     "start_time": "2019-01-18T14:58:27.426437Z"
    }
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Time Series\n",
    "In this lecture, we'll talk about 4 things:\n",
    "* What is a time series?\n",
    "* How does pandas deal with dates/times?\n",
    "* The Special Time Series Functions (that technically can be used elsewhere)\n",
    "* The multiindex (which is especially useful with time series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a time series?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T14:59:33.278081Z",
     "start_time": "2019-01-18T14:59:33.263451Z"
    }
   },
   "outputs": [],
   "source": [
    "#An example\n",
    "pd.read_csv('Rainfall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:00:36.484249Z",
     "start_time": "2019-01-18T15:00:36.477854Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise, make date the index col and read in as `data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:02:18.051333Z",
     "start_time": "2019-01-18T15:02:18.047927Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise, what the data type of the index column?\n",
    "#Hint, similar to numpy notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:02:23.718681Z",
     "start_time": "2019-01-18T15:02:23.710656Z"
    }
   },
   "source": [
    "# Making pandas understand we have a date/time\n",
    "\n",
    "Our index was not of the date time type, and so we don't get access to the special date time operators.\n",
    "Here is how to conver it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:03:51.803994Z",
     "start_time": "2019-01-18T15:03:51.797700Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:04:32.332100Z",
     "start_time": "2019-01-18T15:04:32.327786Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise, set your index to be the datetime version of your index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:04:34.337654Z",
     "start_time": "2019-01-18T15:04:34.330544Z"
    }
   },
   "source": [
    "## Working with date times\n",
    "Why would we care about doing this. Python/Pandas makes math operations with dates very easy. Check these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:05:42.541674Z",
     "start_time": "2019-01-18T15:05:42.535598Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:07:55.162052Z",
     "start_time": "2019-01-18T15:07:55.150362Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:08:20.397179Z",
     "start_time": "2019-01-18T15:08:20.393146Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:08:30.482159Z",
     "start_time": "2019-01-18T15:08:30.476854Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:09:16.680258Z",
     "start_time": "2019-01-18T15:09:16.674286Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index.strftime('%A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:09:16.680258Z",
     "start_time": "2019-01-18T15:09:16.674286Z"
    }
   },
   "source": [
    "https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math With Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:23:41.640145Z",
     "start_time": "2019-01-18T15:23:41.633453Z"
    }
   },
   "outputs": [],
   "source": [
    "data.index - data.index[0]\n",
    "#yields time delta\n",
    "#This could be more useful if you have some experiment and its the number of days running that matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:13:25.017475Z",
     "start_time": "2019-01-18T15:13:25.010228Z"
    }
   },
   "outputs": [],
   "source": [
    "#can do arithmetic with this object\n",
    "(data.index - data.index[0])*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range for dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:14:35.295222Z",
     "start_time": "2019-01-18T15:14:35.289426Z"
    }
   },
   "outputs": [],
   "source": [
    "#Inclusive on both sides\n",
    "pd.date_range('2015-07-03', '2015-07-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:14:41.145990Z",
     "start_time": "2019-01-18T15:14:41.139627Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dates by default\n",
    "pd.date_range('2015-07-03', periods=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:15:13.090065Z",
     "start_time": "2019-01-18T15:15:13.079963Z"
    }
   },
   "outputs": [],
   "source": [
    "#What if we wanted to do every hour?\n",
    "pd.date_range('2015-07-03',periods=8,freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:20:55.157623Z",
     "start_time": "2019-01-18T15:20:55.151311Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise, get me the amount of minutes the government shutdown has been going on for\n",
    "#Hint: It started on December 22 at midnight and is going on until now\n",
    "#Hint2: You can google around how to see how to get the current time in python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:19:35.323671Z",
     "start_time": "2019-01-18T15:19:35.319303Z"
    }
   },
   "source": [
    "# Special Datetime Functions\n",
    "\n",
    "### diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:24:01.430144Z",
     "start_time": "2019-01-18T15:24:01.421854Z"
    }
   },
   "source": [
    "What if we were interested in the change in rainfall day over day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:24:47.977910Z",
     "start_time": "2019-01-18T15:24:47.969192Z"
    }
   },
   "outputs": [],
   "source": [
    "data.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:25:25.781402Z",
     "start_time": "2019-01-18T15:25:25.772815Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise, look into the documentation of diff to get the difference of today and a week before today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:25:56.197081Z",
     "start_time": "2019-01-18T15:25:56.189079Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exericse, use diff to get difference of today and a week after today (i.e. looking into the future)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We can think of diff (with periods=1) as a discretized form of the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:28:12.878901Z",
     "start_time": "2019-01-18T15:28:12.870377Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise: How could we get a discretized form of the second derivative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:29:35.919690Z",
     "start_time": "2019-01-18T15:29:35.910844Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:29:51.516049Z",
     "start_time": "2019-01-18T15:29:51.507539Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:31:30.879731Z",
     "start_time": "2019-01-18T15:31:30.870023Z"
    }
   },
   "outputs": [],
   "source": [
    "#Why might you want to use shift?\n",
    "#Exericse, find a 3 day rolling mean using shift\n",
    "#Hint: You may need to use a negative number in your shift function\n",
    "(data + data.shift() + data.shift(-1))/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we get the total amount of rain so far each day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:32:12.827409Z",
     "start_time": "2019-01-18T15:32:12.818976Z"
    }
   },
   "outputs": [],
   "source": [
    "data.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other cumulative functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:32:50.878820Z",
     "start_time": "2019-01-18T15:32:50.869962Z"
    }
   },
   "outputs": [],
   "source": [
    "data.cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:32:54.610020Z",
     "start_time": "2019-01-18T15:32:54.596934Z"
    }
   },
   "outputs": [],
   "source": [
    "data.cummin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:32:58.710456Z",
     "start_time": "2019-01-18T15:32:58.702002Z"
    }
   },
   "outputs": [],
   "source": [
    "data.cummax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:34:20.356647Z",
     "start_time": "2019-01-18T15:34:20.337329Z"
    }
   },
   "source": [
    "# Chaning windows\n",
    "# 2 options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:37:09.147764Z",
     "start_time": "2019-01-18T15:37:09.139441Z"
    }
   },
   "outputs": [],
   "source": [
    "data.asfreq('D')\n",
    "#acts as if theres value each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:37:29.168839Z",
     "start_time": "2019-01-18T15:37:29.160388Z"
    }
   },
   "outputs": [],
   "source": [
    "data.asfreq('M')\n",
    "#takes value at end of each month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:35:37.619008Z",
     "start_time": "2019-01-18T15:35:37.602057Z"
    }
   },
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:37:27.681740Z",
     "start_time": "2019-01-18T15:37:27.672608Z"
    }
   },
   "outputs": [],
   "source": [
    "data.asfreq('W')\n",
    "#takes value at end of each week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:36:26.008992Z",
     "start_time": "2019-01-18T15:36:26.000660Z"
    }
   },
   "source": [
    "There are some obvious downsides to using `asfreq`\n",
    "Lets talk about something more complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:38:14.930840Z",
     "start_time": "2019-01-18T15:38:14.926593Z"
    }
   },
   "outputs": [],
   "source": [
    "data.resample('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:38:23.246391Z",
     "start_time": "2019-01-18T15:38:23.230640Z"
    }
   },
   "outputs": [],
   "source": [
    "data.resample('W').mean()\n",
    "#What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:38:30.890740Z",
     "start_time": "2019-01-18T15:38:30.880068Z"
    }
   },
   "outputs": [],
   "source": [
    "data.resample('W').apply(np.mean)\n",
    "#We can take any aggregation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In essence, resample is just a groupby for dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we resampled up? I.e. did a frequency that we didn't have info on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:39:57.913640Z",
     "start_time": "2019-01-18T15:39:57.902290Z"
    }
   },
   "outputs": [],
   "source": [
    "data.resample('D').median()\n",
    "# The same as if you called asfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets move to a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:45:39.601083Z",
     "start_time": "2019-01-18T15:45:39.559315Z"
    }
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('lebron.csv')\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:45:40.124138Z",
     "start_time": "2019-01-18T15:45:40.048992Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(data2.Season)\n",
    "#pandas isn't sure what to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:45:40.646868Z",
     "start_time": "2019-01-18T15:45:40.639906Z"
    }
   },
   "outputs": [],
   "source": [
    "#exercise, use the str split function to only get the second year in each date, make sure you year looks like '2018'\n",
    "#then drop the old season column and make your index the years you just got (as a datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:45:41.478762Z",
     "start_time": "2019-01-18T15:45:41.474871Z"
    }
   },
   "outputs": [],
   "source": [
    "#We can rename an index\n",
    "data2.index.name='Season'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:45:45.384376Z",
     "start_time": "2019-01-18T15:45:45.347104Z"
    }
   },
   "source": [
    "# Rolling windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:47:05.778927Z",
     "start_time": "2019-01-18T15:47:05.772982Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.PTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:47:55.751958Z",
     "start_time": "2019-01-18T15:47:55.746335Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.PTS.rolling(3,center=True).mean()\n",
    "#What happend here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:48:18.330360Z",
     "start_time": "2019-01-18T15:48:18.314354Z"
    }
   },
   "outputs": [],
   "source": [
    "#Again, we can apply any aggregation function\n",
    "data2.PTS.rolling(3,center=True).apply(np.median)\n",
    "#What happend here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:48:53.972298Z",
     "start_time": "2019-01-18T15:48:53.965324Z"
    }
   },
   "outputs": [],
   "source": [
    "#What about different window sizes?\n",
    "data2.PTS.rolling(5,center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:49:10.903672Z",
     "start_time": "2019-01-18T15:49:10.896699Z"
    }
   },
   "outputs": [],
   "source": [
    "#What about an even window size?\n",
    "data2.PTS.rolling(2,center=True).mean()\n",
    "#defaults to taking value and value before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:51:12.345779Z",
     "start_time": "2019-01-18T15:51:12.340307Z"
    }
   },
   "outputs": [],
   "source": [
    "#How to get rid of nans and just use what we have?\n",
    "data2.PTS.rolling(2,center=True,min_periods=0).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:54:29.481746Z",
     "start_time": "2019-01-18T15:54:29.442072Z"
    }
   },
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:54:48.214098Z",
     "start_time": "2019-01-18T15:54:48.187006Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.rolling(3).mean()\n",
    "#won't work becuase of text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:55:58.918024Z",
     "start_time": "2019-01-18T15:55:58.860704Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.groupby('Pos').rolling(3).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:59:26.021957Z",
     "start_time": "2019-01-18T15:59:25.976046Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Something fancy\n",
    "\n",
    "#What is this doing?\n",
    "data2.drop(['Lg','Pos'],1).groupby('Tm').rolling(3,center=True,min_periods=0).mean().groupby('Tm').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data in a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:00:30.701150Z",
     "start_time": "2019-01-18T16:00:30.687998Z"
    }
   },
   "outputs": [],
   "source": [
    "#lets look back at data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:00:55.084227Z",
     "start_time": "2019-01-18T16:00:55.076246Z"
    }
   },
   "outputs": [],
   "source": [
    "#just for fun\n",
    "data.iloc[4]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:01:08.613329Z",
     "start_time": "2019-01-18T16:01:08.604337Z"
    }
   },
   "outputs": [],
   "source": [
    "data.fillna(method='bfill')\n",
    "#What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:01:15.469094Z",
     "start_time": "2019-01-18T16:01:15.460662Z"
    }
   },
   "outputs": [],
   "source": [
    "data.fillna(method='ffill')\n",
    "#What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:02:41.288965Z",
     "start_time": "2019-01-18T16:02:41.279146Z"
    }
   },
   "outputs": [],
   "source": [
    "(data.fillna(method='bfill')+data.fillna(method='ffill'))/2\n",
    "#Can do both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The multi index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:08:22.224474Z",
     "start_time": "2019-01-18T16:08:22.218053Z"
    }
   },
   "outputs": [],
   "source": [
    "data_j = pd.read_csv('jordan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:08:47.638489Z",
     "start_time": "2019-01-18T16:08:47.631616Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exercise, do the same exercise for seasons that we did for lebron and set it to index\n",
    "\n",
    "#Exercise, rename your index as 'Season'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:11:47.432738Z",
     "start_time": "2019-01-18T16:11:47.423750Z"
    }
   },
   "outputs": [],
   "source": [
    "#exercise, add a column to the lebron data that is called 'Name' and every entry is 'Lebron'\n",
    "#exercise, add acolumn to the jordan data that is called 'Name' and every entry is 'Jordan'\n",
    "#exercise, concat lebron below jordan (as he should be) into one dataframe called bball\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:11:49.529640Z",
     "start_time": "2019-01-18T16:11:49.478938Z"
    }
   },
   "source": [
    "We have a problem, the dataframe is 2 dimensional but we require 3 dimensions to analyze this dataset properly.\n",
    "Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:13:06.552166Z",
     "start_time": "2019-01-18T16:13:06.546662Z"
    }
   },
   "outputs": [],
   "source": [
    "#How to index by both name and date (in that order)\n",
    "#first, reset the index\n",
    "bball = bball.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:13:19.107702Z",
     "start_time": "2019-01-18T16:13:19.055943Z"
    }
   },
   "outputs": [],
   "source": [
    "bball.set_index(['Name','Season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:13:31.180393Z",
     "start_time": "2019-01-18T16:13:31.174309Z"
    }
   },
   "outputs": [],
   "source": [
    "bball = bball.set_index(['Name','Season'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wahlah, a fake 3-d array in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:14:30.953871Z",
     "start_time": "2019-01-18T16:14:30.915166Z"
    }
   },
   "outputs": [],
   "source": [
    "#how to index\n",
    "#gets us all about jordan\n",
    "bball.loc['Jordan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:15:10.613259Z",
     "start_time": "2019-01-18T16:15:10.605910Z"
    }
   },
   "outputs": [],
   "source": [
    "#what if we just wanted lebron, 2004?\n",
    "bball.loc[('Lebron','2004-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:15:46.776566Z",
     "start_time": "2019-01-18T16:15:46.759601Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exericse, just get lebron 2004, 3P% using just one call of `.loc` and a comma\n",
    "bball.loc[('Lebron','2004-01-01'),'3P%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We can have more than 2 things in our multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:16:55.110911Z",
     "start_time": "2019-01-18T16:16:55.053251Z"
    }
   },
   "outputs": [],
   "source": [
    "bball.reset_index().set_index(['Name','Season','Tm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Power of the Multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:17:32.342905Z",
     "start_time": "2019-01-18T16:17:32.324996Z"
    }
   },
   "outputs": [],
   "source": [
    "#Not what we want!\n",
    "bball.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:17:49.758938Z",
     "start_time": "2019-01-18T16:17:49.735281Z"
    }
   },
   "outputs": [],
   "source": [
    "bball.groupby('Name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:18:05.245490Z",
     "start_time": "2019-01-18T16:18:05.207290Z"
    }
   },
   "outputs": [],
   "source": [
    "bball.groupby('Age').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:22:24.996191Z",
     "start_time": "2019-01-18T16:22:24.942674Z"
    }
   },
   "outputs": [],
   "source": [
    "#Bad!\n",
    "bball.drop(['Tm','Pos','Lg'],1).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:23:01.293001Z",
     "start_time": "2019-01-18T16:23:01.214505Z"
    }
   },
   "outputs": [],
   "source": [
    "#Good!\n",
    "bball.drop(['Tm','Pos','Lg'],1).groupby('Name').cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:23:11.556930Z",
     "start_time": "2019-01-18T16:23:11.507741Z"
    }
   },
   "outputs": [],
   "source": [
    "#rolling wont understand, #look at lebrons first age\n",
    "bball.drop(['Tm','Pos','Lg'],1).rolling(3,center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:23:12.357358Z",
     "start_time": "2019-01-18T16:23:12.296898Z"
    }
   },
   "outputs": [],
   "source": [
    "bball.drop(['Tm','Pos','Lg'],1).groupby('Name').rolling(3,center=True).mean()\n",
    "#Weird name, name thing, but we can deal with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:24:41.176627Z",
     "start_time": "2019-01-18T16:24:41.161776Z"
    }
   },
   "outputs": [],
   "source": [
    "#Odd behavior, how to we get rid of a 'level' of our index?\n",
    "temp = bball.drop(['Tm','Pos','Lg'],1).groupby('Name').rolling(3,center=True).mean()\n",
    "\n",
    "temp.index = temp.index.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:24:52.190706Z",
     "start_time": "2019-01-18T16:24:52.186568Z"
    }
   },
   "outputs": [],
   "source": [
    "temp.index = temp.index.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T16:24:54.125543Z",
     "start_time": "2019-01-18T16:24:54.078583Z"
    }
   },
   "outputs": [],
   "source": [
    "temp\n",
    "#drops from left to right"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[710,720,1430],[650,800,1450],[730,640,1370],[800,770,1570],[690,710,1400]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 710,  720, 1430],\n",
       "       [ 650,  800, 1450],\n",
       "       [ 730,  640, 1370],\n",
       "       [ 800,  770, 1570],\n",
       "       [ 690,  710, 1400]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.matrix_rank(data)\n",
    "#Tells us there are only 2 linearly independent columns\n",
    "#Worthless to have column 3 if we were to do some statistical test, it provides us no new information.\n",
    "#In reality any 2 of the 3 is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 3rd column\n",
    "A = data[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [85,50,87,100,70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(A,y):\n",
    "    #solve A.T A x = A.T y\n",
    "    x = la.pinv(A.T @ (A)) @ (A.T) @ (y)\n",
    "    #pinv essentially does SVD\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24623299 -0.1342156 ]\n"
     ]
    }
   ],
   "source": [
    "x_hat = linear_regression(A,y)\n",
    "print(x_hat)\n",
    "\n",
    "#What kind of test was this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78.19019037, 52.67896359, 93.85209774, 93.64037923, 74.60768662])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions\n",
    "A @ x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.80980963,  2.67896359,  6.85209774, -6.35962077,  4.60768662])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How far off are we?\n",
    "#Remember vectorization\n",
    "(A @ x_hat) - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.80980963, 2.67896359, 6.85209774, 6.35962077, 4.60768662])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check magnitude\n",
    "np.abs((A @ x_hat) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.4616356708840215"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now mean\n",
    "np.abs((A @ x_hat) - y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What if we don't remove the last column\n",
    "x_hat = linear_regression(data,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.461635670884126"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exactly the same error\n",
    "np.abs((data @ x_hat) - y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20889386, -0.17155473,  0.03733913])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3rd Feature is barely used\n",
    "x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In real datasets without dumb things like this you won't see linearly independent data, but you will see highly correlated data which causes trouble but wastes. \n",
    "\n",
    "### We will talk about ways to compress your data to only keep whats useful in the 3rd week. Called \"dimensionality reduction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net\n",
    "Lets create that neural net from the slides with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    z_cop = z.copy()\n",
    "    z_cop[z_cop<0] = 0\n",
    "    return z_cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[710, 720],\n",
       "       [650, 800],\n",
       "       [730, 640],\n",
       "       [800, 770],\n",
       "       [690, 710]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(2,5)\n",
    "W2 = np.random.randn(5,7)\n",
    "W0 = np.random.randn(7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(A,W1,W2,W0):\n",
    "    H_1 = ReLU(A@W1)\n",
    "    H_2 = ReLU(H_1@W2)\n",
    "    output = H_2 @ W0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -960.15417986],\n",
       "       [ -860.63848325],\n",
       "       [-1000.28442209],\n",
       "       [-1087.24800531],\n",
       "       [ -931.76614205]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Really bad, don't need to check mean error to confirm that, but this is because we haven't updated our random weights\n",
    "neural_net(A,W1,W2,W0)\n",
    "#This isn't a task for a neural network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
